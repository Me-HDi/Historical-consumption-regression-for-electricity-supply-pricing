{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Irs2cLNNNCov"
   },
   "source": [
    "# Data Challenge : Historical consumption regression for electricity supply pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the other notebook for data preprocessing details and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-0623253a9761>:50: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  df['weekofyear'] = df.index.weekofyear\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import calendar\n",
    "import math\n",
    "import holidays\n",
    "\n",
    "\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "#Import training data\n",
    "inputFilePath = \"./input_training_ssnsrY0.csv\"\n",
    "data_train = pd.read_csv(inputFilePath, delimiter = ',', skiprows = 0, index_col=[0])\n",
    "\n",
    "#Import testing data\n",
    "inputFilePathTest = \"./input_test_cdKcI0e.csv\"\n",
    "data_test = pd.read_csv(inputFilePathTest, delimiter = ',', skiprows = 0, index_col=[0])\n",
    "id_test = data_test.index\n",
    "# import targets\n",
    "outputFilePath = \"./output_training_Uf11I9I.csv\"\n",
    "targets = pd.read_csv(outputFilePath, delimiter = ',', skiprows = 0, index_col=[0])\n",
    "\n",
    "#Remove useless datas\n",
    "data_train = data_train.drop([\"loc_1\", \"loc_2\", \"loc_secondary_1\", \"loc_secondary_2\", \"loc_secondary_3\"], axis = 1)\n",
    "data_test = data_test.drop([\"loc_1\", \"loc_2\", \"loc_secondary_1\", \"loc_secondary_2\", \"loc_secondary_3\"], axis = 1)\n",
    "\n",
    "data_train.timestamp = pd.to_datetime(data_train.timestamp)\n",
    "data_test.timestamp = pd.to_datetime(data_test.timestamp)\n",
    "\n",
    "fr_holidays = holidays.France()\n",
    "data_train['isHoliday'] = data_train.timestamp.apply(lambda x:1 if x in fr_holidays else 0)\n",
    "data_test['isHoliday'] = data_test.timestamp.apply(lambda x:1 if x in fr_holidays else 0)\n",
    "\n",
    "\n",
    "# indexing with timestamp\n",
    "data_test = data_test.set_index('timestamp')\n",
    "data_train = data_train.set_index('timestamp')\n",
    "\n",
    "# time features\n",
    "def timefeatures(df):\n",
    "    df['hour'] = df.index.hour\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofmonth'] = df.index.day\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['weekofyear'] = df.index.weekofyear\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "\n",
    "    return df\n",
    "\n",
    "data_train = timefeatures(data_train)\n",
    "data_test = timefeatures(data_test)\n",
    "\n",
    "# isWeekend feature\n",
    "data_train['isWeekend'] = data_train['dayofweek'].apply(lambda x: 1 if x in [5,6] else 0)\n",
    "data_test['isWeekend'] = data_test['dayofweek'].apply(lambda x: 1 if x in [5,6] else 0)\n",
    "\n",
    "# smoothing temp and humidity\n",
    "data_train['temp_1_smooth7D'] = data_train['temp_1'].interpolate().rolling(24*7).mean().fillna(method='bfill').round(decimals=1)\n",
    "data_train['temp_2_smooth7D'] = data_train['temp_2'].interpolate().rolling(24*7).mean().fillna(method='bfill').round(decimals=1)\n",
    "data_test['temp_1_smooth7D'] = data_test['temp_1'].interpolate().rolling(24*7).mean().fillna(method='bfill').round(decimals=1)\n",
    "data_test['temp_2_smooth7D'] = data_test['temp_2'].interpolate().rolling(24*7).mean().fillna(method='bfill').round(decimals=1)\n",
    "\n",
    "data_train['humidity_1_smooth7D'] = data_train['humidity_1'].interpolate().rolling(24*7).mean().fillna(method='bfill').round()\n",
    "data_train['humidity_2_smooth7D'] = data_train['humidity_2'].interpolate().rolling(24*7).mean().fillna(method='bfill').round()\n",
    "data_test['humidity_1_smooth7D'] = data_test['humidity_1'].interpolate().rolling(24*7).mean().fillna(method='bfill').round()\n",
    "data_test['humidity_2_smooth7D'] = data_test['humidity_2'].interpolate().rolling(24*7).mean().fillna(method='bfill').round()\n",
    "\n",
    "# concatenate features and targets\n",
    "data_train = pd.concat([targets.set_index(data_train.index), data_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "features_lm_loc1 = ['hour','isHoliday','weekofyear', 'month','consumption_secondary_1', 'consumption_secondary_2',\n",
    "       'consumption_secondary_3', 'temp_1_smooth7D','humidity_1_smooth7D']\n",
    "\n",
    "features_lm_loc2 = features_lm_loc1\n",
    "\n",
    "# training data\n",
    "X_train1 = data_train[features_lm_loc1]\n",
    "X_train2 = data_train[features_lm_loc2]\n",
    "# training labels\n",
    "y_train1 = data_train['consumption_1']\n",
    "y_train2 = data_train['consumption_2']\n",
    "\n",
    "# test data\n",
    "X_test1 = data_test[features_lm_loc1]\n",
    "X_test2 = data_test[features_lm_loc2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_1={'n_estimators': 100,\n",
    " 'min_child_weight': 7,\n",
    " 'metric': 'l2',\n",
    " 'max_depth': 8,\n",
    " 'learning_rate': 0.05,\n",
    " 'gamma': 0.2,\n",
    " 'colsample_bytree': 0.4}\n",
    "#Estimated from random search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "sAK4L-wtNCt-",
    "outputId": "480c02d0-1638-4393-f9f4-e369cb690180"
   },
   "outputs": [],
   "source": [
    "# Initialisation of the model with the optimal parameters\n",
    "reg = xgb.XGBRegressor(**hyper_params_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { metric } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## prediction for Lille (1)\n",
    "reg.fit(X_train1, y_train1)\n",
    "y_pred1 = reg.predict(X_test1)\n",
    "y_pred1_df = pd.DataFrame(y_pred1, index=data_test.index, columns=['pred1']) # save data in a DataFrame format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9.847181\n"
     ]
    }
   ],
   "source": [
    "# Calculat the mean squared error between training and prediction data\n",
    "y_train_pred1 = reg.predict(X_train1)\n",
    "rmse = np.sqrt(mean_squared_error(y_train1, y_train_pred1)) ## mse for the training\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { metric } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## prediction for Aix (2)\n",
    "reg.fit(X_train2, y_train2)\n",
    "y_pred2 = reg.predict(X_test2)\n",
    "y_pred2_df = pd.DataFrame(y_pred2, index=data_test.index, columns=['pred2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.032691\n"
     ]
    }
   ],
   "source": [
    "y_train_pred2 = reg.predict(X_train2)\n",
    "rmse = np.sqrt(mean_squared_error(y_train2, y_train_pred2)) ## mse for the training\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## create the submission csv file\n",
    "sub2 = pd.concat([y_pred1_df, y_pred2_df], axis=1).set_index(id_test)\n",
    "sub2.set_index(data_test.index, inplace=True )\n",
    "sub2.to_csv('submission_xgb.csv')\n",
    "## resulting accuracy in the data challenge 19.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tunning for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For localisation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "params={\n",
    " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"n_estimators\"     : range(50,300,50),\n",
    " \"max_depth\"        : [ 2,3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ],\n",
    " 'metric': ['l2', 'auc']}\n",
    "\n",
    "# We have used random search instead of grid search to optimise calculating time \n",
    "random_search=RandomizedSearchCV(reg,\n",
    "                                param_distributions=params,\n",
    "                               n_iter=5,                           \n",
    "                               n_jobs=-1, \n",
    "                               cv=5,\n",
    "                               random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { metric } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_child_weight': 1,\n",
       " 'metric': 'l2',\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.1,\n",
       " 'gamma': 0.0,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train1, y_train1)\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor(**random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { metric } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## prediction for Lille (1)\n",
    "reg.fit(X_train1, y_train1)\n",
    "y_pred1 = reg.predict(X_test1)\n",
    "y_pred1_df = pd.DataFrame(y_pred1, index=data_test.index, columns=['pred1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.646539\n"
     ]
    }
   ],
   "source": [
    "# the metric used to evaluate the model\n",
    "y_train_pred1 = reg.predict(X_train1)\n",
    "rmse = np.sqrt(mean_squared_error(y_train1, y_train_pred1)) ## mse of the training\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For localisation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { metric } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_child_weight': 1,\n",
       " 'metric': 'l2',\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.1,\n",
       " 'gamma': 0.0,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train2, y_train2)\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = xgb.XGBRegressor(**random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { metric } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## prediction for Aix (2)\n",
    "reg.fit(X_train2, y_train2)\n",
    "y_pred2 = reg.predict(X_test2)\n",
    "y_pred2_df = pd.DataFrame(y_pred2, index=data_test.index, columns=['pred2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.679853\n"
     ]
    }
   ],
   "source": [
    "# the metric used to evaluate the model\n",
    "y_train_pred2 = reg.predict(X_train2)\n",
    "rmse = np.sqrt(mean_squared_error(y_train2, y_train_pred2)) ## mse for the training\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the submission csv file\n",
    "sub3 = pd.concat([y_pred1_df, y_pred2_df], axis=1).set_index(id_test)\n",
    "sub3.to_csv('submission_xgb_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
